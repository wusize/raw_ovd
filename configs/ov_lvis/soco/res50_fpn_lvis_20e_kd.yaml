_BASE_: "./base_res50_fpn_lvis_1x.yaml"
MODEL:
  CLIP:
    USE_IMAGE_ENCODER: True

SOLVER:
  STEPS: (100000, 133333)
  MAX_ITER: 150000
  CHECKPOINT_PERIOD: 10000

CONTEXT_MODELLING:
  ENABLE: True
  CONTRAST_LOSS_WEIGHT: 1.0
  TOKEN_LOSS_WEIGHT: 0.1
  POSITIONAL_ENCODING: True
  CE_TEMP: 30.0
  TOKEN_TEMP: 50.0
  QUEUE:
    LENGTHS: [1024, 1024, 1024, 1024]
    NAMES: ['clip_text_features', 'clip_image_features', 'clip_word_features', 'clip_patch_features']
